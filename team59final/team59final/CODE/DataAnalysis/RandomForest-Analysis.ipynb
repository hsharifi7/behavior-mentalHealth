{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('dataConsolidatedClean.csv')\n",
    "data = pd.read_csv('dataConsolidatedCleanNoIFV.csv')\n",
    "\n",
    "# Separate out the x_data and y_data.\n",
    "X_data = data.loc[:, data.columns != \"mentalhealth\"]\n",
    "y_data = data.loc[:, \"mentalhealth\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The random state to use while splitting the data.\n",
    "random_state = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 70% of the data into training and 30% into test sets. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, train_size=0.70, test_size=0.30, random_state=100, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RandomForestClassifier and train it.\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_predict_train = clf.predict(X_train)\n",
    "y_predict_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6823493708993136\n",
      "0.6814301413939998\n"
     ]
    }
   ],
   "source": [
    "# Test its accuracy on the training set using the accuracy_score method.\n",
    "# Test its accuracy on the test set using the accuracy_score method.\n",
    "print(accuracy_score(y_train, y_predict_train.round()))\n",
    "print(accuracy_score(y_test, y_predict_test.round()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most importan is smoke. Least important is vegetable\n"
     ]
    }
   ],
   "source": [
    "# Determine the feature importance as evaluated by the Random Forest Classifier.\n",
    "# Sort them in the descending order and print the feature numbers. The report the most important and the least important feature.\n",
    "# Mention the features with the exact names, e.g. X11, X1, etc.\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "\n",
    "print(\"Most importan is %s. Least important is %s\" % (x_data.columns[indices[0]], x_data.columns[indices[x_data.shape[1]-1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. feature smoke (0.539548)\n",
      "2. feature workout (0.210570)\n",
      "3. feature internet (0.123733)\n",
      "4. feature education (0.073323)\n",
      "5. feature state (0.026237)\n",
      "6. feature index (0.018720)\n",
      "7. feature year (0.002629)\n",
      "8. feature fruit (0.002529)\n",
      "9. feature drink (0.002359)\n",
      "10. feature vegetable (0.000352)\n"
     ]
    }
   ],
   "source": [
    "for f in range(x_data.shape[1]):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, x_data.columns[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing some attributes\n",
    "X_data = X_data.loc[:, X_data.columns != \"index\"]\n",
    "X_train = X_train.loc[:, X_train.columns != \"index\"]\n",
    "X_test = X_test.loc[:, X_test.columns != \"index\"]\n",
    "\n",
    "X_data = X_data.loc[:, X_data.columns != \"year\"]\n",
    "X_train = X_train.loc[:, X_train.columns != \"year\"]\n",
    "X_test = X_test.loc[:, X_test.columns != \"year\"]\n",
    "\n",
    "X_data = X_data.loc[:, X_data.columns != \"state\"]\n",
    "X_train = X_train.loc[:, X_train.columns != \"state\"]\n",
    "X_test = X_test.loc[:, X_test.columns != \"state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params  {'max_depth': 1, 'n_estimators': 5}\n",
      "best_score  0.6864178865762234\n"
     ]
    }
   ],
   "source": [
    "# Tune the hyper-parameters 'n_estimators' and 'max_depth'.\n",
    "parameters = {'n_estimators':[5, 10, 12], 'max_depth':[1, 2,3]}\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "gsCV = GridSearchCV(clf, parameters, cv=10)\n",
    "gsCV.fit(X_train, y_train)\n",
    "sorted(gsCV.cv_results_.keys())\n",
    "print(\"best_params \", gsCV.best_params_)\n",
    "print(\"best_score \", gsCV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
